{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, Bidirectional\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import numpy as np "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'and': 1, 'the': 2, 'a': 3, 'in': 4, 'all': 5, 'i': 6, 'for': 7, 'of': 8, 'lanigans': 9, 'ball': 10, 'were': 11, 'at': 12, 'to': 13, 'she': 14, 'stepped': 15, 'his': 16, 'girls': 17, 'as': 18, 'they': 19, 'til': 20, 'he': 21, 'again': 22, 'got': 23, 'boys': 24, 'round': 25, 'that': 26, 'her': 27, 'there': 28, 'three': 29, 'weeks': 30, 'up': 31, 'out': 32, 'him': 33, 'was': 34, 'spent': 35, 'learning': 36, 'new': 37, 'steps': 38, 'long': 39, 'away': 40, 'left': 41, 'friends': 42, 'relations': 43, 'when': 44, 'wall': 45, 'myself': 46, 'nice': 47, 'just': 48, 'dancing': 49, 'merry': 50, 'tipped': 51, 'me': 52, 'soon': 53, 'time': 54, 'old': 55, 'their': 56, 'them': 57, 'danced': 58, 'dublin': 59, 'an': 60, 'put': 61, 'leg': 62, 'miss': 63, 'fainted': 64, 'from': 65, 'town': 66, 'athy': 67, 'one': 68, 'jeremy': 69, 'lanigan': 70, 'battered': 71, 'hadnt': 72, 'pound': 73, 'father': 74, 'died': 75, 'made': 76, 'man': 77, 'farm': 78, 'ten': 79, 'acres': 80, 'ground': 81, 'gave': 82, 'grand': 83, 'party': 84, 'who': 85, 'didnt': 86, 'forget': 87, 'come': 88, 'if': 89, 'youll': 90, 'but': 91, 'listen': 92, 'ill': 93, 'make': 94, 'your': 95, 'eyes': 96, 'glisten': 97, 'rows': 98, 'ructions': 99, 'be': 100, 'sure': 101, 'free': 102, 'invitation': 103, 'might': 104, 'ask': 105, 'minute': 106, 'both': 107, 'bees': 108, 'cask': 109, 'judy': 110, 'odaly': 111, 'little': 112, 'milliner': 113, 'wink': 114, 'give': 115, 'call': 116, 'arrived': 117, 'with': 118, 'peggy': 119, 'mcgilligan': 120, 'lashings': 121, 'punch': 122, 'wine': 123, 'ladies': 124, 'potatoes': 125, 'cakes': 126, 'bacon': 127, 'tea': 128, 'nolans': 129, 'dolans': 130, 'ogradys': 131, 'courting': 132, 'songs': 133, 'went': 134, 'plenty': 135, 'water': 136, 'harp': 137, 'once': 138, 'sounded': 139, 'taras': 140, 'hall': 141, 'sweet': 142, 'nelly': 143, 'gray': 144, 'rat': 145, 'catchers': 146, 'daughter': 147, 'singing': 148, 'together': 149, 'doing': 150, 'kinds': 151, 'nonsensical': 152, 'polkas': 153, 'room': 154, 'whirligig': 155, 'julia': 156, 'we': 157, 'banished': 158, 'nonsense': 159, 'twist': 160, 'reel': 161, 'jig': 162, 'ach': 163, 'mavrone': 164, 'how': 165, 'mad': 166, 'youd': 167, 'think': 168, 'ceiling': 169, 'would': 170, 'fall': 171, 'brooks': 172, 'academy': 173, 'learn': 174, 'nothing': 175, 'hearty': 176, 'around': 177, 'couples': 178, 'groups': 179, 'accident': 180, 'happened': 181, 'young': 182, 'terrance': 183, 'mccarthy': 184, 'right': 185, 'through': 186, 'finnertys': 187, 'hoops': 188, 'poor': 189, 'creature': 190, 'cried': 191, 'meelia': 192, 'murther': 193, 'called': 194, 'brothers': 195, 'gathered': 196, 'carmody': 197, 'swore': 198, 'hed': 199, 'go': 200, 'no': 201, 'further': 202, 'had': 203, 'satisfaction': 204, 'midst': 205, 'row': 206, 'kerrigan': 207, 'cheeks': 208, 'same': 209, 'red': 210, 'rose': 211, 'some': 212, 'lads': 213, 'declared': 214, 'painted': 215, 'took': 216, 'small': 217, 'drop': 218, 'too': 219, 'much': 220, 'suppose': 221, 'sweetheart': 222, 'ned': 223, 'morgan': 224, 'so': 225, 'powerful': 226, 'able': 227, 'saw': 228, 'fair': 229, 'colleen': 230, 'stretched': 231, 'by': 232, 'tore': 233, 'under': 234, 'table': 235, 'smashed': 236, 'chaneys': 237, 'oh': 238, 'twas': 239, 'then': 240, 'runctions': 241, 'lick': 242, 'big': 243, 'phelim': 244, 'mchugh': 245, 'replied': 246, 'introduction': 247, 'kicked': 248, 'terrible': 249, 'hullabaloo': 250, 'casey': 251, 'piper': 252, 'near': 253, 'being': 254, 'strangled': 255, 'squeezed': 256, 'pipes': 257, 'bellows': 258, 'chanters': 259, 'ribbons': 260, 'entangled': 261, 'end': 262}\n",
      "263\n"
     ]
    }
   ],
   "source": [
    "tokenizer = Tokenizer()\n",
    "\n",
    "data=\"In the town of Athy one Jeremy Lanigan \\n Battered away til he hadnt a pound. \\nHis father died and made him a man again \\n Left him a farm and ten acres of ground. \\nHe gave a grand party for friends and relations \\nWho didnt forget him when come to the wall, \\nAnd if youll but listen Ill make your eyes glisten \\nOf the rows and the ructions of Lanigans Ball. \\nMyself to be sure got free invitation, \\nFor all the nice girls and boys I might ask, \\nAnd just in a minute both friends and relations \\nWere dancing round merry as bees round a cask. \\nJudy ODaly, that nice little milliner, \\nShe tipped me a wink for to give her a call, \\nAnd I soon arrived with Peggy McGilligan \\nJust in time for Lanigans Ball. \\nThere were lashings of punch and wine for the ladies, \\nPotatoes and cakes; there was bacon and tea, \\nThere were the Nolans, Dolans, OGradys \\nCourting the girls and dancing away. \\nSongs they went round as plenty as water, \\nThe harp that once sounded in Taras old hall,\\nSweet Nelly Gray and The Rat Catchers Daughter,\\nAll singing together at Lanigans Ball. \\nThey were doing all kinds of nonsensical polkas \\nAll round the room in a whirligig. \\nJulia and I, we banished their nonsense \\nAnd tipped them the twist of a reel and a jig. \\nAch mavrone, how the girls got all mad at me \\nDanced til youd think the ceiling would fall. \\nFor I spent three weeks at Brooks Academy \\nLearning new steps for Lanigans Ball. \\nThree long weeks I spent up in Dublin, \\nThree long weeks to learn nothing at all,\\n Three long weeks I spent up in Dublin, \\nLearning new steps for Lanigans Ball. \\nShe stepped out and I stepped in again, \\nI stepped out and she stepped in again, \\nShe stepped out and I stepped in again, \\nLearning new steps for Lanigans Ball. \\nBoys were all merry and the girls they were hearty \\nAnd danced all around in couples and groups, \\nTil an accident happened, young Terrance McCarthy \\nPut his right leg through miss Finnertys hoops. \\nPoor creature fainted and cried Meelia murther, \\nCalled for her brothers and gathered them all. \\nCarmody swore that hed go no further \\nTil he had satisfaction at Lanigans Ball. \\nIn the midst of the row miss Kerrigan fainted, \\nHer cheeks at the same time as red as a rose. \\nSome of the lads declared she was painted, \\nShe took a small drop too much, I suppose. \\nHer sweetheart, Ned Morgan, so powerful and able, \\nWhen he saw his fair colleen stretched out by the wall, \\nTore the left leg from under the table \\nAnd smashed all the Chaneys at Lanigans Ball. \\nBoys, oh boys, twas then there were runctions. \\nMyself got a lick from big Phelim McHugh. \\nI soon replied to his introduction \\nAnd kicked up a terrible hullabaloo. \\nOld Casey, the piper, was near being strangled. \\nThey squeezed up his pipes, bellows, chanters and all. \\nThe girls, in their ribbons, they got all entangled \\nAnd that put an end to Lanigans Ball.\"\n",
    "\n",
    "corpus = data.lower().split(\"\\n\")\n",
    "\n",
    "tokenizer.fit_on_texts(corpus)\n",
    "total_words = len(tokenizer.word_index) + 1\n",
    "\n",
    "print(tokenizer.word_index)\n",
    "print(total_words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_sequences = []\n",
    "for line in corpus:\n",
    "    token_list = tokenizer.texts_to_sequences([line])[0]\n",
    "    for i in range(1, len(token_list)):\n",
    "        n_gram_sequence = token_list[:i+1]\n",
    "        input_sequences.append(n_gram_sequence)\n",
    "\n",
    "# pad sequences \n",
    "max_sequence_len = max([len(x) for x in input_sequences])\n",
    "input_sequences = np.array(pad_sequences(input_sequences, maxlen=max_sequence_len, padding='pre'))\n",
    "\n",
    "# create predictors and label\n",
    "xs, labels = input_sequences[:,:-1],input_sequences[:,-1]\n",
    "\n",
    "ys = tf.keras.utils.to_categorical(labels, num_classes=total_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "2\n",
      "66\n",
      "8\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.word_index['in'])\n",
    "print(tokenizer.word_index['the'])\n",
    "print(tokenizer.word_index['town'])\n",
    "print(tokenizer.word_index['of'])\n",
    "print(tokenizer.word_index['athy'])\n",
    "print(tokenizer.word_index['one'])\n",
    "print(tokenizer.word_index['jeremy'])\n",
    "print(tokenizer.word_index['lanigan'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0  0  0  4  2 66  8 67 68 69]\n"
     ]
    }
   ],
   "source": [
    "print(xs[6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "print(ys[6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0  0  0  0  4  2 66  8 67 68]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "print(xs[5])\n",
    "print(ys[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'and': 1, 'the': 2, 'a': 3, 'in': 4, 'all': 5, 'i': 6, 'for': 7, 'of': 8, 'lanigans': 9, 'ball': 10, 'were': 11, 'at': 12, 'to': 13, 'she': 14, 'stepped': 15, 'his': 16, 'girls': 17, 'as': 18, 'they': 19, 'til': 20, 'he': 21, 'again': 22, 'got': 23, 'boys': 24, 'round': 25, 'that': 26, 'her': 27, 'there': 28, 'three': 29, 'weeks': 30, 'up': 31, 'out': 32, 'him': 33, 'was': 34, 'spent': 35, 'learning': 36, 'new': 37, 'steps': 38, 'long': 39, 'away': 40, 'left': 41, 'friends': 42, 'relations': 43, 'when': 44, 'wall': 45, 'myself': 46, 'nice': 47, 'just': 48, 'dancing': 49, 'merry': 50, 'tipped': 51, 'me': 52, 'soon': 53, 'time': 54, 'old': 55, 'their': 56, 'them': 57, 'danced': 58, 'dublin': 59, 'an': 60, 'put': 61, 'leg': 62, 'miss': 63, 'fainted': 64, 'from': 65, 'town': 66, 'athy': 67, 'one': 68, 'jeremy': 69, 'lanigan': 70, 'battered': 71, 'hadnt': 72, 'pound': 73, 'father': 74, 'died': 75, 'made': 76, 'man': 77, 'farm': 78, 'ten': 79, 'acres': 80, 'ground': 81, 'gave': 82, 'grand': 83, 'party': 84, 'who': 85, 'didnt': 86, 'forget': 87, 'come': 88, 'if': 89, 'youll': 90, 'but': 91, 'listen': 92, 'ill': 93, 'make': 94, 'your': 95, 'eyes': 96, 'glisten': 97, 'rows': 98, 'ructions': 99, 'be': 100, 'sure': 101, 'free': 102, 'invitation': 103, 'might': 104, 'ask': 105, 'minute': 106, 'both': 107, 'bees': 108, 'cask': 109, 'judy': 110, 'odaly': 111, 'little': 112, 'milliner': 113, 'wink': 114, 'give': 115, 'call': 116, 'arrived': 117, 'with': 118, 'peggy': 119, 'mcgilligan': 120, 'lashings': 121, 'punch': 122, 'wine': 123, 'ladies': 124, 'potatoes': 125, 'cakes': 126, 'bacon': 127, 'tea': 128, 'nolans': 129, 'dolans': 130, 'ogradys': 131, 'courting': 132, 'songs': 133, 'went': 134, 'plenty': 135, 'water': 136, 'harp': 137, 'once': 138, 'sounded': 139, 'taras': 140, 'hall': 141, 'sweet': 142, 'nelly': 143, 'gray': 144, 'rat': 145, 'catchers': 146, 'daughter': 147, 'singing': 148, 'together': 149, 'doing': 150, 'kinds': 151, 'nonsensical': 152, 'polkas': 153, 'room': 154, 'whirligig': 155, 'julia': 156, 'we': 157, 'banished': 158, 'nonsense': 159, 'twist': 160, 'reel': 161, 'jig': 162, 'ach': 163, 'mavrone': 164, 'how': 165, 'mad': 166, 'youd': 167, 'think': 168, 'ceiling': 169, 'would': 170, 'fall': 171, 'brooks': 172, 'academy': 173, 'learn': 174, 'nothing': 175, 'hearty': 176, 'around': 177, 'couples': 178, 'groups': 179, 'accident': 180, 'happened': 181, 'young': 182, 'terrance': 183, 'mccarthy': 184, 'right': 185, 'through': 186, 'finnertys': 187, 'hoops': 188, 'poor': 189, 'creature': 190, 'cried': 191, 'meelia': 192, 'murther': 193, 'called': 194, 'brothers': 195, 'gathered': 196, 'carmody': 197, 'swore': 198, 'hed': 199, 'go': 200, 'no': 201, 'further': 202, 'had': 203, 'satisfaction': 204, 'midst': 205, 'row': 206, 'kerrigan': 207, 'cheeks': 208, 'same': 209, 'red': 210, 'rose': 211, 'some': 212, 'lads': 213, 'declared': 214, 'painted': 215, 'took': 216, 'small': 217, 'drop': 218, 'too': 219, 'much': 220, 'suppose': 221, 'sweetheart': 222, 'ned': 223, 'morgan': 224, 'so': 225, 'powerful': 226, 'able': 227, 'saw': 228, 'fair': 229, 'colleen': 230, 'stretched': 231, 'by': 232, 'tore': 233, 'under': 234, 'table': 235, 'smashed': 236, 'chaneys': 237, 'oh': 238, 'twas': 239, 'then': 240, 'runctions': 241, 'lick': 242, 'big': 243, 'phelim': 244, 'mchugh': 245, 'replied': 246, 'introduction': 247, 'kicked': 248, 'terrible': 249, 'hullabaloo': 250, 'casey': 251, 'piper': 252, 'near': 253, 'being': 254, 'strangled': 255, 'squeezed': 256, 'pipes': 257, 'bellows': 258, 'chanters': 259, 'ribbons': 260, 'entangled': 261, 'end': 262}\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.word_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 453 samples\n",
      "Epoch 1/500\n",
      "453/453 [==============================] - 6s 13ms/sample - loss: 5.5671 - accuracy: 0.0221\n",
      "Epoch 2/500\n",
      "453/453 [==============================] - 0s 478us/sample - loss: 5.5390 - accuracy: 0.0508\n",
      "Epoch 3/500\n",
      "453/453 [==============================] - 0s 478us/sample - loss: 5.4599 - accuracy: 0.0508\n",
      "Epoch 4/500\n",
      "453/453 [==============================] - 0s 501us/sample - loss: 5.2514 - accuracy: 0.0508\n",
      "Epoch 5/500\n",
      "453/453 [==============================] - 0s 525us/sample - loss: 5.1088 - accuracy: 0.0508\n",
      "Epoch 6/500\n",
      "453/453 [==============================] - 0s 526us/sample - loss: 5.0621 - accuracy: 0.0508\n",
      "Epoch 7/500\n",
      "453/453 [==============================] - 0s 561us/sample - loss: 5.0268 - accuracy: 0.0375\n",
      "Epoch 8/500\n",
      "453/453 [==============================] - 0s 535us/sample - loss: 4.9982 - accuracy: 0.0486\n",
      "Epoch 9/500\n",
      "453/453 [==============================] - 0s 566us/sample - loss: 4.9654 - accuracy: 0.0486\n",
      "Epoch 10/500\n",
      "453/453 [==============================] - 0s 515us/sample - loss: 4.9300 - accuracy: 0.0508\n",
      "Epoch 11/500\n",
      "453/453 [==============================] - 0s 522us/sample - loss: 4.8900 - accuracy: 0.0596\n",
      "Epoch 12/500\n",
      "453/453 [==============================] - 0s 546us/sample - loss: 4.8526 - accuracy: 0.0486\n",
      "Epoch 13/500\n",
      "453/453 [==============================] - 0s 553us/sample - loss: 4.8046 - accuracy: 0.0552\n",
      "Epoch 14/500\n",
      "453/453 [==============================] - 0s 556us/sample - loss: 4.7557 - accuracy: 0.0530\n",
      "Epoch 15/500\n",
      "453/453 [==============================] - 0s 503us/sample - loss: 4.7111 - accuracy: 0.0596\n",
      "Epoch 16/500\n",
      "453/453 [==============================] - 0s 552us/sample - loss: 4.6492 - accuracy: 0.0640\n",
      "Epoch 17/500\n",
      "453/453 [==============================] - 0s 526us/sample - loss: 4.5989 - accuracy: 0.0839\n",
      "Epoch 18/500\n",
      "453/453 [==============================] - 0s 537us/sample - loss: 4.5524 - accuracy: 0.0883\n",
      "Epoch 19/500\n",
      "453/453 [==============================] - 0s 520us/sample - loss: 4.5115 - accuracy: 0.0905\n",
      "Epoch 20/500\n",
      "453/453 [==============================] - 0s 570us/sample - loss: 4.4666 - accuracy: 0.0883\n",
      "Epoch 21/500\n",
      "453/453 [==============================] - 0s 513us/sample - loss: 4.4302 - accuracy: 0.0949\n",
      "Epoch 22/500\n",
      "453/453 [==============================] - 0s 533us/sample - loss: 4.4093 - accuracy: 0.0971\n",
      "Epoch 23/500\n",
      "453/453 [==============================] - 0s 579us/sample - loss: 4.3676 - accuracy: 0.0993\n",
      "Epoch 24/500\n",
      "453/453 [==============================] - 0s 526us/sample - loss: 4.3375 - accuracy: 0.1060\n",
      "Epoch 25/500\n",
      "453/453 [==============================] - 0s 515us/sample - loss: 4.2848 - accuracy: 0.1082\n",
      "Epoch 26/500\n",
      "453/453 [==============================] - 0s 517us/sample - loss: 4.2537 - accuracy: 0.1170\n",
      "Epoch 27/500\n",
      "453/453 [==============================] - 0s 509us/sample - loss: 4.2171 - accuracy: 0.1082\n",
      "Epoch 28/500\n",
      "453/453 [==============================] - 0s 513us/sample - loss: 4.1636 - accuracy: 0.1192\n",
      "Epoch 29/500\n",
      "453/453 [==============================] - 0s 506us/sample - loss: 4.1245 - accuracy: 0.1214\n",
      "Epoch 30/500\n",
      "453/453 [==============================] - 0s 505us/sample - loss: 4.0862 - accuracy: 0.1214\n",
      "Epoch 31/500\n",
      "453/453 [==============================] - 0s 504us/sample - loss: 4.0582 - accuracy: 0.1192\n",
      "Epoch 32/500\n",
      "453/453 [==============================] - 0s 506us/sample - loss: 4.0224 - accuracy: 0.1236\n",
      "Epoch 33/500\n",
      "453/453 [==============================] - 0s 509us/sample - loss: 3.9777 - accuracy: 0.1325\n",
      "Epoch 34/500\n",
      "453/453 [==============================] - 0s 509us/sample - loss: 3.9467 - accuracy: 0.1567 - loss: 3.9843 - accuracy: \n",
      "Epoch 35/500\n",
      "453/453 [==============================] - 0s 513us/sample - loss: 3.9103 - accuracy: 0.1634\n",
      "Epoch 36/500\n",
      "453/453 [==============================] - 0s 507us/sample - loss: 3.8764 - accuracy: 0.1656\n",
      "Epoch 37/500\n",
      "453/453 [==============================] - 0s 591us/sample - loss: 3.8423 - accuracy: 0.1722\n",
      "Epoch 38/500\n",
      "453/453 [==============================] - 0s 555us/sample - loss: 3.8038 - accuracy: 0.1854\n",
      "Epoch 39/500\n",
      "453/453 [==============================] - 0s 707us/sample - loss: 3.7674 - accuracy: 0.1965\n",
      "Epoch 40/500\n",
      "453/453 [==============================] - 0s 582us/sample - loss: 3.7349 - accuracy: 0.1876\n",
      "Epoch 41/500\n",
      "453/453 [==============================] - 0s 513us/sample - loss: 3.7057 - accuracy: 0.1943\n",
      "Epoch 42/500\n",
      "453/453 [==============================] - 0s 610us/sample - loss: 3.6670 - accuracy: 0.2053\n",
      "Epoch 43/500\n",
      "453/453 [==============================] - 0s 720us/sample - loss: 3.6265 - accuracy: 0.2208\n",
      "Epoch 44/500\n",
      "453/453 [==============================] - 0s 733us/sample - loss: 3.5921 - accuracy: 0.2185\n",
      "Epoch 45/500\n",
      "453/453 [==============================] - 0s 806us/sample - loss: 3.5541 - accuracy: 0.2340\n",
      "Epoch 46/500\n",
      "453/453 [==============================] - 0s 709us/sample - loss: 3.5201 - accuracy: 0.2362\n",
      "Epoch 47/500\n",
      "453/453 [==============================] - 0s 568us/sample - loss: 3.4824 - accuracy: 0.2384\n",
      "Epoch 48/500\n",
      "453/453 [==============================] - 0s 720us/sample - loss: 3.4473 - accuracy: 0.2362\n",
      "Epoch 49/500\n",
      "453/453 [==============================] - 0s 531us/sample - loss: 3.4145 - accuracy: 0.2318\n",
      "Epoch 50/500\n",
      "453/453 [==============================] - 0s 678us/sample - loss: 3.3844 - accuracy: 0.2539\n",
      "Epoch 51/500\n",
      "453/453 [==============================] - 0s 621us/sample - loss: 3.3523 - accuracy: 0.2583\n",
      "Epoch 52/500\n",
      "453/453 [==============================] - 0s 511us/sample - loss: 3.3132 - accuracy: 0.2848\n",
      "Epoch 53/500\n",
      "453/453 [==============================] - 0s 502us/sample - loss: 3.2818 - accuracy: 0.2870\n",
      "Epoch 54/500\n",
      "453/453 [==============================] - 0s 489us/sample - loss: 3.2508 - accuracy: 0.2980\n",
      "Epoch 55/500\n",
      "453/453 [==============================] - 0s 513us/sample - loss: 3.2222 - accuracy: 0.3046\n",
      "Epoch 56/500\n",
      "453/453 [==============================] - 0s 491us/sample - loss: 3.1885 - accuracy: 0.3289\n",
      "Epoch 57/500\n",
      "453/453 [==============================] - 0s 495us/sample - loss: 3.1510 - accuracy: 0.3289\n",
      "Epoch 58/500\n",
      "453/453 [==============================] - 0s 495us/sample - loss: 3.1177 - accuracy: 0.3444\n",
      "Epoch 59/500\n",
      "453/453 [==============================] - 0s 496us/sample - loss: 3.0853 - accuracy: 0.3554\n",
      "Epoch 60/500\n",
      "453/453 [==============================] - 0s 502us/sample - loss: 3.0550 - accuracy: 0.3532\n",
      "Epoch 61/500\n",
      "453/453 [==============================] - 0s 523us/sample - loss: 3.0186 - accuracy: 0.3753\n",
      "Epoch 62/500\n",
      "453/453 [==============================] - 0s 487us/sample - loss: 2.9878 - accuracy: 0.3974\n",
      "Epoch 63/500\n",
      "453/453 [==============================] - 0s 509us/sample - loss: 2.9669 - accuracy: 0.3974\n",
      "Epoch 64/500\n",
      "453/453 [==============================] - 0s 503us/sample - loss: 2.9258 - accuracy: 0.4018\n",
      "Epoch 65/500\n",
      "453/453 [==============================] - 0s 495us/sample - loss: 2.8884 - accuracy: 0.4018\n",
      "Epoch 66/500\n",
      "453/453 [==============================] - 0s 496us/sample - loss: 2.8469 - accuracy: 0.4150\n",
      "Epoch 67/500\n",
      "453/453 [==============================] - 0s 489us/sample - loss: 2.8145 - accuracy: 0.4371\n",
      "Epoch 68/500\n",
      "453/453 [==============================] - 0s 511us/sample - loss: 2.7980 - accuracy: 0.4150 - loss: 2.7275 - accuracy: \n",
      "Epoch 69/500\n",
      "453/453 [==============================] - 0s 494us/sample - loss: 2.7758 - accuracy: 0.4283\n",
      "Epoch 70/500\n",
      "453/453 [==============================] - 0s 481us/sample - loss: 2.7327 - accuracy: 0.4415\n",
      "Epoch 71/500\n",
      "453/453 [==============================] - 0s 496us/sample - loss: 2.7084 - accuracy: 0.4437\n",
      "Epoch 72/500\n",
      "453/453 [==============================] - 0s 483us/sample - loss: 2.6968 - accuracy: 0.4459\n",
      "Epoch 73/500\n",
      "453/453 [==============================] - 0s 495us/sample - loss: 2.6861 - accuracy: 0.4459\n",
      "Epoch 74/500\n",
      "453/453 [==============================] - 0s 484us/sample - loss: 2.6550 - accuracy: 0.4636\n",
      "Epoch 75/500\n",
      "453/453 [==============================] - 0s 500us/sample - loss: 2.6254 - accuracy: 0.4702\n",
      "Epoch 76/500\n",
      "453/453 [==============================] - 0s 493us/sample - loss: 2.5811 - accuracy: 0.4812\n",
      "Epoch 77/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "453/453 [==============================] - 0s 470us/sample - loss: 2.5649 - accuracy: 0.4967\n",
      "Epoch 78/500\n",
      "453/453 [==============================] - 0s 454us/sample - loss: 2.5204 - accuracy: 0.4879\n",
      "Epoch 79/500\n",
      "453/453 [==============================] - 0s 413us/sample - loss: 2.4863 - accuracy: 0.5077\n",
      "Epoch 80/500\n",
      "453/453 [==============================] - 0s 501us/sample - loss: 2.4631 - accuracy: 0.5364\n",
      "Epoch 81/500\n",
      "453/453 [==============================] - 0s 459us/sample - loss: 2.4333 - accuracy: 0.5364\n",
      "Epoch 82/500\n",
      "453/453 [==============================] - 0s 460us/sample - loss: 2.4056 - accuracy: 0.5298\n",
      "Epoch 83/500\n",
      "453/453 [==============================] - 0s 478us/sample - loss: 2.3760 - accuracy: 0.5541\n",
      "Epoch 84/500\n",
      "453/453 [==============================] - 0s 462us/sample - loss: 2.3549 - accuracy: 0.5629\n",
      "Epoch 85/500\n",
      "453/453 [==============================] - 0s 460us/sample - loss: 2.3264 - accuracy: 0.5828\n",
      "Epoch 86/500\n",
      "453/453 [==============================] - 0s 465us/sample - loss: 2.2997 - accuracy: 0.5740\n",
      "Epoch 87/500\n",
      "453/453 [==============================] - 0s 461us/sample - loss: 2.2694 - accuracy: 0.5960\n",
      "Epoch 88/500\n",
      "453/453 [==============================] - 0s 466us/sample - loss: 2.2513 - accuracy: 0.5916\n",
      "Epoch 89/500\n",
      "453/453 [==============================] - 0s 456us/sample - loss: 2.2292 - accuracy: 0.5938\n",
      "Epoch 90/500\n",
      "453/453 [==============================] - 0s 458us/sample - loss: 2.2001 - accuracy: 0.6004\n",
      "Epoch 91/500\n",
      "453/453 [==============================] - 0s 476us/sample - loss: 2.1759 - accuracy: 0.6004\n",
      "Epoch 92/500\n",
      "453/453 [==============================] - 0s 460us/sample - loss: 2.1577 - accuracy: 0.6071\n",
      "Epoch 93/500\n",
      "453/453 [==============================] - 0s 458us/sample - loss: 2.1396 - accuracy: 0.6159\n",
      "Epoch 94/500\n",
      "453/453 [==============================] - 0s 476us/sample - loss: 2.1162 - accuracy: 0.6203\n",
      "Epoch 95/500\n",
      "453/453 [==============================] - 0s 460us/sample - loss: 2.1090 - accuracy: 0.6225\n",
      "Epoch 96/500\n",
      "453/453 [==============================] - 0s 456us/sample - loss: 2.0796 - accuracy: 0.6225\n",
      "Epoch 97/500\n",
      "453/453 [==============================] - 0s 456us/sample - loss: 2.0788 - accuracy: 0.6203\n",
      "Epoch 98/500\n",
      "453/453 [==============================] - 0s 471us/sample - loss: 2.0549 - accuracy: 0.6269\n",
      "Epoch 99/500\n",
      "453/453 [==============================] - 0s 460us/sample - loss: 2.0271 - accuracy: 0.6358\n",
      "Epoch 100/500\n",
      "453/453 [==============================] - 0s 456us/sample - loss: 1.9994 - accuracy: 0.6380\n",
      "Epoch 101/500\n",
      "453/453 [==============================] - 0s 471us/sample - loss: 1.9794 - accuracy: 0.6424\n",
      "Epoch 102/500\n",
      "453/453 [==============================] - 0s 456us/sample - loss: 1.9489 - accuracy: 0.6534\n",
      "Epoch 103/500\n",
      "453/453 [==============================] - 0s 467us/sample - loss: 1.9268 - accuracy: 0.6446\n",
      "Epoch 104/500\n",
      "453/453 [==============================] - 0s 456us/sample - loss: 1.9016 - accuracy: 0.6512\n",
      "Epoch 105/500\n",
      "453/453 [==============================] - 0s 469us/sample - loss: 1.8919 - accuracy: 0.6534\n",
      "Epoch 106/500\n",
      "453/453 [==============================] - 0s 453us/sample - loss: 1.8760 - accuracy: 0.6667\n",
      "Epoch 107/500\n",
      "453/453 [==============================] - 0s 480us/sample - loss: 1.8548 - accuracy: 0.6843\n",
      "Epoch 108/500\n",
      "453/453 [==============================] - 0s 471us/sample - loss: 1.8380 - accuracy: 0.6755\n",
      "Epoch 109/500\n",
      "453/453 [==============================] - 0s 449us/sample - loss: 1.8142 - accuracy: 0.6821\n",
      "Epoch 110/500\n",
      "453/453 [==============================] - 0s 478us/sample - loss: 1.7898 - accuracy: 0.6821\n",
      "Epoch 111/500\n",
      "453/453 [==============================] - 0s 465us/sample - loss: 1.7692 - accuracy: 0.6865 - loss: 1.7794 - accuracy: 0.67\n",
      "Epoch 112/500\n",
      "453/453 [==============================] - 0s 462us/sample - loss: 1.7479 - accuracy: 0.6998\n",
      "Epoch 113/500\n",
      "453/453 [==============================] - 0s 467us/sample - loss: 1.7265 - accuracy: 0.6998\n",
      "Epoch 114/500\n",
      "453/453 [==============================] - 0s 458us/sample - loss: 1.7062 - accuracy: 0.7020\n",
      "Epoch 115/500\n",
      "453/453 [==============================] - 0s 462us/sample - loss: 1.6865 - accuracy: 0.7174\n",
      "Epoch 116/500\n",
      "453/453 [==============================] - 0s 460us/sample - loss: 1.6705 - accuracy: 0.7263\n",
      "Epoch 117/500\n",
      "453/453 [==============================] - 0s 471us/sample - loss: 1.6516 - accuracy: 0.7263\n",
      "Epoch 118/500\n",
      "453/453 [==============================] - 0s 462us/sample - loss: 1.6346 - accuracy: 0.7285\n",
      "Epoch 119/500\n",
      "453/453 [==============================] - 0s 465us/sample - loss: 1.6141 - accuracy: 0.7329\n",
      "Epoch 120/500\n",
      "453/453 [==============================] - 0s 460us/sample - loss: 1.5953 - accuracy: 0.7351\n",
      "Epoch 121/500\n",
      "453/453 [==============================] - 0s 460us/sample - loss: 1.5784 - accuracy: 0.7219\n",
      "Epoch 122/500\n",
      "453/453 [==============================] - 0s 456us/sample - loss: 1.5596 - accuracy: 0.7263\n",
      "Epoch 123/500\n",
      "453/453 [==============================] - 0s 460us/sample - loss: 1.5441 - accuracy: 0.7351\n",
      "Epoch 124/500\n",
      "453/453 [==============================] - 0s 456us/sample - loss: 1.5265 - accuracy: 0.7329\n",
      "Epoch 125/500\n",
      "453/453 [==============================] - 0s 467us/sample - loss: 1.5320 - accuracy: 0.7483\n",
      "Epoch 126/500\n",
      "453/453 [==============================] - 0s 463us/sample - loss: 1.5280 - accuracy: 0.7439\n",
      "Epoch 127/500\n",
      "453/453 [==============================] - 0s 456us/sample - loss: 1.5164 - accuracy: 0.7506\n",
      "Epoch 128/500\n",
      "453/453 [==============================] - 0s 460us/sample - loss: 1.4890 - accuracy: 0.7572\n",
      "Epoch 129/500\n",
      "453/453 [==============================] - 0s 462us/sample - loss: 1.4712 - accuracy: 0.7660\n",
      "Epoch 130/500\n",
      "453/453 [==============================] - 0s 473us/sample - loss: 1.4590 - accuracy: 0.7528\n",
      "Epoch 131/500\n",
      "453/453 [==============================] - 0s 455us/sample - loss: 1.4366 - accuracy: 0.7550\n",
      "Epoch 132/500\n",
      "453/453 [==============================] - 0s 456us/sample - loss: 1.4136 - accuracy: 0.7572\n",
      "Epoch 133/500\n",
      "453/453 [==============================] - 0s 475us/sample - loss: 1.4006 - accuracy: 0.7638\n",
      "Epoch 134/500\n",
      "453/453 [==============================] - 0s 457us/sample - loss: 1.3778 - accuracy: 0.7682\n",
      "Epoch 135/500\n",
      "453/453 [==============================] - 0s 465us/sample - loss: 1.3628 - accuracy: 0.7770\n",
      "Epoch 136/500\n",
      "453/453 [==============================] - 0s 469us/sample - loss: 1.3461 - accuracy: 0.7947\n",
      "Epoch 137/500\n",
      "453/453 [==============================] - 0s 460us/sample - loss: 1.3334 - accuracy: 0.7903\n",
      "Epoch 138/500\n",
      "453/453 [==============================] - 0s 467us/sample - loss: 1.3164 - accuracy: 0.7881\n",
      "Epoch 139/500\n",
      "453/453 [==============================] - 0s 454us/sample - loss: 1.3052 - accuracy: 0.8057\n",
      "Epoch 140/500\n",
      "453/453 [==============================] - 0s 472us/sample - loss: 1.3082 - accuracy: 0.8013\n",
      "Epoch 141/500\n",
      "453/453 [==============================] - 0s 469us/sample - loss: 1.2919 - accuracy: 0.8057\n",
      "Epoch 142/500\n",
      "453/453 [==============================] - 0s 454us/sample - loss: 1.2808 - accuracy: 0.8102\n",
      "Epoch 143/500\n",
      "453/453 [==============================] - 0s 473us/sample - loss: 1.2905 - accuracy: 0.7947\n",
      "Epoch 144/500\n",
      "453/453 [==============================] - 0s 449us/sample - loss: 1.3188 - accuracy: 0.7925\n",
      "Epoch 145/500\n",
      "453/453 [==============================] - 0s 471us/sample - loss: 1.2984 - accuracy: 0.7815\n",
      "Epoch 146/500\n",
      "453/453 [==============================] - 0s 454us/sample - loss: 1.2647 - accuracy: 0.7925\n",
      "Epoch 147/500\n",
      "453/453 [==============================] - 0s 473us/sample - loss: 1.2287 - accuracy: 0.8168\n",
      "Epoch 148/500\n",
      "453/453 [==============================] - 0s 469us/sample - loss: 1.2135 - accuracy: 0.8102\n",
      "Epoch 149/500\n",
      "453/453 [==============================] - 0s 460us/sample - loss: 1.1892 - accuracy: 0.8234\n",
      "Epoch 150/500\n",
      "453/453 [==============================] - 0s 469us/sample - loss: 1.1711 - accuracy: 0.8278\n",
      "Epoch 151/500\n",
      "453/453 [==============================] - 0s 462us/sample - loss: 1.1553 - accuracy: 0.8234 - loss: 1.1463 - accuracy: 0.83\n",
      "Epoch 152/500\n",
      "453/453 [==============================] - 0s 465us/sample - loss: 1.1448 - accuracy: 0.8278\n",
      "Epoch 153/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "453/453 [==============================] - 0s 469us/sample - loss: 1.1339 - accuracy: 0.8344\n",
      "Epoch 154/500\n",
      "453/453 [==============================] - 0s 465us/sample - loss: 1.1184 - accuracy: 0.8366\n",
      "Epoch 155/500\n",
      "453/453 [==============================] - 0s 460us/sample - loss: 1.1037 - accuracy: 0.8344\n",
      "Epoch 156/500\n",
      "453/453 [==============================] - 0s 466us/sample - loss: 1.0921 - accuracy: 0.8477\n",
      "Epoch 157/500\n",
      "453/453 [==============================] - 0s 456us/sample - loss: 1.0779 - accuracy: 0.8433\n",
      "Epoch 158/500\n",
      "453/453 [==============================] - 0s 455us/sample - loss: 1.0659 - accuracy: 0.8455\n",
      "Epoch 159/500\n",
      "453/453 [==============================] - 0s 462us/sample - loss: 1.0525 - accuracy: 0.8477\n",
      "Epoch 160/500\n",
      "453/453 [==============================] - 0s 451us/sample - loss: 1.0413 - accuracy: 0.8499\n",
      "Epoch 161/500\n",
      "453/453 [==============================] - 0s 462us/sample - loss: 1.0317 - accuracy: 0.8477\n",
      "Epoch 162/500\n",
      "453/453 [==============================] - 0s 458us/sample - loss: 1.0203 - accuracy: 0.8411\n",
      "Epoch 163/500\n",
      "453/453 [==============================] - 0s 451us/sample - loss: 1.0081 - accuracy: 0.8543\n",
      "Epoch 164/500\n",
      "453/453 [==============================] - 0s 465us/sample - loss: 0.9971 - accuracy: 0.8609\n",
      "Epoch 165/500\n",
      "453/453 [==============================] - 0s 449us/sample - loss: 0.9850 - accuracy: 0.8609\n",
      "Epoch 166/500\n",
      "453/453 [==============================] - 0s 456us/sample - loss: 0.9763 - accuracy: 0.8631\n",
      "Epoch 167/500\n",
      "453/453 [==============================] - 0s 465us/sample - loss: 0.9696 - accuracy: 0.8631\n",
      "Epoch 168/500\n",
      "453/453 [==============================] - 0s 454us/sample - loss: 0.9605 - accuracy: 0.8631\n",
      "Epoch 169/500\n",
      "453/453 [==============================] - 0s 465us/sample - loss: 0.9478 - accuracy: 0.8675\n",
      "Epoch 170/500\n",
      "453/453 [==============================] - 0s 451us/sample - loss: 0.9405 - accuracy: 0.8675\n",
      "Epoch 171/500\n",
      "453/453 [==============================] - 0s 467us/sample - loss: 0.9326 - accuracy: 0.8742 - loss: 0.9489 - accuracy: 0.87\n",
      "Epoch 172/500\n",
      "453/453 [==============================] - 0s 458us/sample - loss: 0.9266 - accuracy: 0.8653\n",
      "Epoch 173/500\n",
      "453/453 [==============================] - 0s 449us/sample - loss: 0.9148 - accuracy: 0.8675\n",
      "Epoch 174/500\n",
      "453/453 [==============================] - 0s 469us/sample - loss: 0.9028 - accuracy: 0.8742\n",
      "Epoch 175/500\n",
      "453/453 [==============================] - 0s 456us/sample - loss: 0.8938 - accuracy: 0.8742\n",
      "Epoch 176/500\n",
      "453/453 [==============================] - 0s 465us/sample - loss: 0.8998 - accuracy: 0.8742\n",
      "Epoch 177/500\n",
      "453/453 [==============================] - 0s 451us/sample - loss: 0.8986 - accuracy: 0.8764\n",
      "Epoch 178/500\n",
      "453/453 [==============================] - 0s 456us/sample - loss: 0.8937 - accuracy: 0.8653\n",
      "Epoch 179/500\n",
      "453/453 [==============================] - 0s 462us/sample - loss: 0.9193 - accuracy: 0.8675\n",
      "Epoch 180/500\n",
      "453/453 [==============================] - 0s 456us/sample - loss: 0.8979 - accuracy: 0.8852\n",
      "Epoch 181/500\n",
      "453/453 [==============================] - 0s 471us/sample - loss: 0.8784 - accuracy: 0.8764\n",
      "Epoch 182/500\n",
      "453/453 [==============================] - 0s 452us/sample - loss: 0.8576 - accuracy: 0.8786\n",
      "Epoch 183/500\n",
      "453/453 [==============================] - 0s 458us/sample - loss: 0.8364 - accuracy: 0.8764\n",
      "Epoch 184/500\n",
      "453/453 [==============================] - 0s 456us/sample - loss: 0.8286 - accuracy: 0.8852\n",
      "Epoch 185/500\n",
      "453/453 [==============================] - 0s 473us/sample - loss: 0.8152 - accuracy: 0.8896\n",
      "Epoch 186/500\n",
      "453/453 [==============================] - 0s 454us/sample - loss: 0.8019 - accuracy: 0.8962\n",
      "Epoch 187/500\n",
      "453/453 [==============================] - 0s 460us/sample - loss: 0.7928 - accuracy: 0.8896\n",
      "Epoch 188/500\n",
      "453/453 [==============================] - 0s 462us/sample - loss: 0.7827 - accuracy: 0.8918\n",
      "Epoch 189/500\n",
      "453/453 [==============================] - 0s 465us/sample - loss: 0.7736 - accuracy: 0.8918\n",
      "Epoch 190/500\n",
      "453/453 [==============================] - 0s 458us/sample - loss: 0.7633 - accuracy: 0.8918\n",
      "Epoch 191/500\n",
      "453/453 [==============================] - 0s 456us/sample - loss: 0.7567 - accuracy: 0.8940\n",
      "Epoch 192/500\n",
      "453/453 [==============================] - 0s 451us/sample - loss: 0.7493 - accuracy: 0.8985\n",
      "Epoch 193/500\n",
      "453/453 [==============================] - 0s 458us/sample - loss: 0.7392 - accuracy: 0.9073\n",
      "Epoch 194/500\n",
      "453/453 [==============================] - 0s 460us/sample - loss: 0.7297 - accuracy: 0.9051\n",
      "Epoch 195/500\n",
      "453/453 [==============================] - 0s 458us/sample - loss: 0.7225 - accuracy: 0.9051\n",
      "Epoch 196/500\n",
      "453/453 [==============================] - 0s 454us/sample - loss: 0.7159 - accuracy: 0.9051\n",
      "Epoch 197/500\n",
      "453/453 [==============================] - 0s 462us/sample - loss: 0.7082 - accuracy: 0.9051\n",
      "Epoch 198/500\n",
      "453/453 [==============================] - 0s 456us/sample - loss: 0.7033 - accuracy: 0.9007\n",
      "Epoch 199/500\n",
      "453/453 [==============================] - 0s 460us/sample - loss: 0.6934 - accuracy: 0.9073\n",
      "Epoch 200/500\n",
      "453/453 [==============================] - 0s 457us/sample - loss: 0.6884 - accuracy: 0.9073\n",
      "Epoch 201/500\n",
      "453/453 [==============================] - 0s 465us/sample - loss: 0.6829 - accuracy: 0.9073\n",
      "Epoch 202/500\n",
      "453/453 [==============================] - 0s 458us/sample - loss: 0.6858 - accuracy: 0.9073\n",
      "Epoch 203/500\n",
      "453/453 [==============================] - 0s 478us/sample - loss: 0.6848 - accuracy: 0.9095\n",
      "Epoch 204/500\n",
      "453/453 [==============================] - 0s 460us/sample - loss: 0.6733 - accuracy: 0.9117\n",
      "Epoch 205/500\n",
      "453/453 [==============================] - 0s 465us/sample - loss: 0.6598 - accuracy: 0.9117\n",
      "Epoch 206/500\n",
      "453/453 [==============================] - 0s 470us/sample - loss: 0.6504 - accuracy: 0.9139\n",
      "Epoch 207/500\n",
      "453/453 [==============================] - 0s 449us/sample - loss: 0.6435 - accuracy: 0.9161\n",
      "Epoch 208/500\n",
      "453/453 [==============================] - 0s 465us/sample - loss: 0.6375 - accuracy: 0.9161\n",
      "Epoch 209/500\n",
      "453/453 [==============================] - 0s 458us/sample - loss: 0.6303 - accuracy: 0.9117\n",
      "Epoch 210/500\n",
      "453/453 [==============================] - 0s 465us/sample - loss: 0.6222 - accuracy: 0.9161\n",
      "Epoch 211/500\n",
      "453/453 [==============================] - 0s 454us/sample - loss: 0.6161 - accuracy: 0.9205\n",
      "Epoch 212/500\n",
      "453/453 [==============================] - 0s 471us/sample - loss: 0.6100 - accuracy: 0.9227\n",
      "Epoch 213/500\n",
      "453/453 [==============================] - 0s 458us/sample - loss: 0.6046 - accuracy: 0.9249\n",
      "Epoch 214/500\n",
      "453/453 [==============================] - 0s 467us/sample - loss: 0.6040 - accuracy: 0.9117\n",
      "Epoch 215/500\n",
      "453/453 [==============================] - 0s 456us/sample - loss: 0.5998 - accuracy: 0.9161\n",
      "Epoch 216/500\n",
      "453/453 [==============================] - 0s 473us/sample - loss: 0.5983 - accuracy: 0.9205\n",
      "Epoch 217/500\n",
      "453/453 [==============================] - 0s 456us/sample - loss: 0.5954 - accuracy: 0.9183\n",
      "Epoch 218/500\n",
      "453/453 [==============================] - 0s 465us/sample - loss: 0.5858 - accuracy: 0.9272\n",
      "Epoch 219/500\n",
      "453/453 [==============================] - 0s 460us/sample - loss: 0.5764 - accuracy: 0.9249\n",
      "Epoch 220/500\n",
      "453/453 [==============================] - 0s 456us/sample - loss: 0.5698 - accuracy: 0.9183\n",
      "Epoch 221/500\n",
      "453/453 [==============================] - 0s 454us/sample - loss: 0.5621 - accuracy: 0.9249\n",
      "Epoch 222/500\n",
      "453/453 [==============================] - 0s 462us/sample - loss: 0.5576 - accuracy: 0.9249\n",
      "Epoch 223/500\n",
      "453/453 [==============================] - 0s 501us/sample - loss: 0.5509 - accuracy: 0.9249\n",
      "Epoch 224/500\n",
      "453/453 [==============================] - 0s 473us/sample - loss: 0.5504 - accuracy: 0.9294\n",
      "Epoch 225/500\n",
      "453/453 [==============================] - 0s 476us/sample - loss: 0.5479 - accuracy: 0.9249\n",
      "Epoch 226/500\n",
      "453/453 [==============================] - 0s 473us/sample - loss: 0.5369 - accuracy: 0.9272\n",
      "Epoch 227/500\n",
      "453/453 [==============================] - 0s 480us/sample - loss: 0.5328 - accuracy: 0.9249\n",
      "Epoch 228/500\n",
      "453/453 [==============================] - 0s 476us/sample - loss: 0.5269 - accuracy: 0.9249\n",
      "Epoch 229/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "453/453 [==============================] - 0s 544us/sample - loss: 0.5213 - accuracy: 0.9183\n",
      "Epoch 230/500\n",
      "453/453 [==============================] - 0s 515us/sample - loss: 0.5180 - accuracy: 0.9183\n",
      "Epoch 231/500\n",
      "453/453 [==============================] - 0s 522us/sample - loss: 0.5125 - accuracy: 0.9183\n",
      "Epoch 232/500\n",
      "453/453 [==============================] - 0s 588us/sample - loss: 0.5074 - accuracy: 0.9249\n",
      "Epoch 233/500\n",
      "453/453 [==============================] - 0s 521us/sample - loss: 0.5012 - accuracy: 0.9294\n",
      "Epoch 234/500\n",
      "453/453 [==============================] - 0s 568us/sample - loss: 0.4953 - accuracy: 0.9249\n",
      "Epoch 235/500\n",
      "453/453 [==============================] - 0s 517us/sample - loss: 0.4906 - accuracy: 0.9249\n",
      "Epoch 236/500\n",
      "453/453 [==============================] - 0s 485us/sample - loss: 0.4858 - accuracy: 0.9272\n",
      "Epoch 237/500\n",
      "453/453 [==============================] - 0s 498us/sample - loss: 0.4812 - accuracy: 0.9294\n",
      "Epoch 238/500\n",
      "453/453 [==============================] - 0s 489us/sample - loss: 0.4788 - accuracy: 0.9272\n",
      "Epoch 239/500\n",
      "453/453 [==============================] - 0s 553us/sample - loss: 0.4801 - accuracy: 0.9316\n",
      "Epoch 240/500\n",
      "453/453 [==============================] - 0s 687us/sample - loss: 0.4823 - accuracy: 0.9249\n",
      "Epoch 241/500\n",
      "453/453 [==============================] - 0s 586us/sample - loss: 0.4910 - accuracy: 0.9227\n",
      "Epoch 242/500\n",
      "453/453 [==============================] - 0s 817us/sample - loss: 0.4976 - accuracy: 0.9294 - loss: 0.4612 - accura\n",
      "Epoch 243/500\n",
      "453/453 [==============================] - 0s 604us/sample - loss: 0.4767 - accuracy: 0.9272\n",
      "Epoch 244/500\n",
      "453/453 [==============================] - 0s 812us/sample - loss: 0.4659 - accuracy: 0.9294\n",
      "Epoch 245/500\n",
      "453/453 [==============================] - 0s 545us/sample - loss: 0.5332 - accuracy: 0.9139\n",
      "Epoch 246/500\n",
      "453/453 [==============================] - 0s 553us/sample - loss: 0.5806 - accuracy: 0.9073\n",
      "Epoch 247/500\n",
      "453/453 [==============================] - 0s 506us/sample - loss: 0.5991 - accuracy: 0.8985\n",
      "Epoch 248/500\n",
      "453/453 [==============================] - 0s 518us/sample - loss: 0.5619 - accuracy: 0.9073\n",
      "Epoch 249/500\n",
      "453/453 [==============================] - 0s 616us/sample - loss: 0.5201 - accuracy: 0.9183\n",
      "Epoch 250/500\n",
      "453/453 [==============================] - 0s 613us/sample - loss: 0.4812 - accuracy: 0.9249\n",
      "Epoch 251/500\n",
      "453/453 [==============================] - 0s 618us/sample - loss: 0.4650 - accuracy: 0.9316\n",
      "Epoch 252/500\n",
      "453/453 [==============================] - 0s 476us/sample - loss: 0.4592 - accuracy: 0.9360\n",
      "Epoch 253/500\n",
      "453/453 [==============================] - 0s 464us/sample - loss: 0.4464 - accuracy: 0.9382\n",
      "Epoch 254/500\n",
      "453/453 [==============================] - 0s 502us/sample - loss: 0.4394 - accuracy: 0.9316\n",
      "Epoch 255/500\n",
      "453/453 [==============================] - 0s 676us/sample - loss: 0.4363 - accuracy: 0.9360 - loss: 0.4303 - accuracy: 0.93\n",
      "Epoch 256/500\n",
      "453/453 [==============================] - 0s 531us/sample - loss: 0.4286 - accuracy: 0.9404\n",
      "Epoch 257/500\n",
      "453/453 [==============================] - 0s 492us/sample - loss: 0.4395 - accuracy: 0.9294\n",
      "Epoch 258/500\n",
      "453/453 [==============================] - 0s 458us/sample - loss: 0.4211 - accuracy: 0.9360\n",
      "Epoch 259/500\n",
      "453/453 [==============================] - 0s 598us/sample - loss: 0.4136 - accuracy: 0.9382\n",
      "Epoch 260/500\n",
      "453/453 [==============================] - 0s 592us/sample - loss: 0.4079 - accuracy: 0.9448\n",
      "Epoch 261/500\n",
      "453/453 [==============================] - 0s 509us/sample - loss: 0.4019 - accuracy: 0.9426\n",
      "Epoch 262/500\n",
      "453/453 [==============================] - 0s 482us/sample - loss: 0.3979 - accuracy: 0.9426\n",
      "Epoch 263/500\n",
      "453/453 [==============================] - 0s 501us/sample - loss: 0.3933 - accuracy: 0.9404\n",
      "Epoch 264/500\n",
      "453/453 [==============================] - 0s 586us/sample - loss: 0.3888 - accuracy: 0.9404\n",
      "Epoch 265/500\n",
      "453/453 [==============================] - 0s 479us/sample - loss: 0.3867 - accuracy: 0.9382\n",
      "Epoch 266/500\n",
      "453/453 [==============================] - 0s 467us/sample - loss: 0.3854 - accuracy: 0.9426\n",
      "Epoch 267/500\n",
      "453/453 [==============================] - 0s 489us/sample - loss: 0.3800 - accuracy: 0.9426\n",
      "Epoch 268/500\n",
      "453/453 [==============================] - 0s 493us/sample - loss: 0.3796 - accuracy: 0.9382\n",
      "Epoch 269/500\n",
      "453/453 [==============================] - 0s 524us/sample - loss: 0.3805 - accuracy: 0.9426\n",
      "Epoch 270/500\n",
      "453/453 [==============================] - 0s 482us/sample - loss: 0.3840 - accuracy: 0.9404\n",
      "Epoch 271/500\n",
      "453/453 [==============================] - 0s 473us/sample - loss: 0.3844 - accuracy: 0.9404\n",
      "Epoch 272/500\n",
      "453/453 [==============================] - 0s 509us/sample - loss: 0.3790 - accuracy: 0.9382\n",
      "Epoch 273/500\n",
      "453/453 [==============================] - 0s 473us/sample - loss: 0.3690 - accuracy: 0.9382\n",
      "Epoch 274/500\n",
      "453/453 [==============================] - 0s 461us/sample - loss: 0.3662 - accuracy: 0.9404\n",
      "Epoch 275/500\n",
      "453/453 [==============================] - 0s 489us/sample - loss: 0.3603 - accuracy: 0.9448\n",
      "Epoch 276/500\n",
      "453/453 [==============================] - 0s 542us/sample - loss: 0.3550 - accuracy: 0.9470\n",
      "Epoch 277/500\n",
      "453/453 [==============================] - 0s 482us/sample - loss: 0.3514 - accuracy: 0.9448\n",
      "Epoch 278/500\n",
      "453/453 [==============================] - 0s 473us/sample - loss: 0.3499 - accuracy: 0.9492\n",
      "Epoch 279/500\n",
      "453/453 [==============================] - 0s 476us/sample - loss: 0.3464 - accuracy: 0.9382\n",
      "Epoch 280/500\n",
      "453/453 [==============================] - 0s 473us/sample - loss: 0.3433 - accuracy: 0.9426\n",
      "Epoch 281/500\n",
      "453/453 [==============================] - 0s 493us/sample - loss: 0.3400 - accuracy: 0.9470\n",
      "Epoch 282/500\n",
      "453/453 [==============================] - 0s 550us/sample - loss: 0.3375 - accuracy: 0.9404\n",
      "Epoch 283/500\n",
      "453/453 [==============================] - 0s 533us/sample - loss: 0.3352 - accuracy: 0.9448\n",
      "Epoch 284/500\n",
      "453/453 [==============================] - 0s 520us/sample - loss: 0.3337 - accuracy: 0.9382\n",
      "Epoch 285/500\n",
      "453/453 [==============================] - 0s 902us/sample - loss: 0.3297 - accuracy: 0.9426\n",
      "Epoch 286/500\n",
      "453/453 [==============================] - 0s 471us/sample - loss: 0.3254 - accuracy: 0.9492\n",
      "Epoch 287/500\n",
      "453/453 [==============================] - 0s 659us/sample - loss: 0.3245 - accuracy: 0.9470\n",
      "Epoch 288/500\n",
      "453/453 [==============================] - 0s 531us/sample - loss: 0.3213 - accuracy: 0.9492\n",
      "Epoch 289/500\n",
      "453/453 [==============================] - 0s 521us/sample - loss: 0.3189 - accuracy: 0.9404\n",
      "Epoch 290/500\n",
      "453/453 [==============================] - 0s 757us/sample - loss: 0.3161 - accuracy: 0.9426\n",
      "Epoch 291/500\n",
      "453/453 [==============================] - 0s 492us/sample - loss: 0.3131 - accuracy: 0.9492\n",
      "Epoch 292/500\n",
      "453/453 [==============================] - 0s 473us/sample - loss: 0.3120 - accuracy: 0.9426\n",
      "Epoch 293/500\n",
      "453/453 [==============================] - 0s 462us/sample - loss: 0.3148 - accuracy: 0.9470\n",
      "Epoch 294/500\n",
      "453/453 [==============================] - 0s 498us/sample - loss: 0.3089 - accuracy: 0.9470\n",
      "Epoch 295/500\n",
      "453/453 [==============================] - 0s 463us/sample - loss: 0.3051 - accuracy: 0.9448\n",
      "Epoch 296/500\n",
      "453/453 [==============================] - 0s 496us/sample - loss: 0.3037 - accuracy: 0.9426\n",
      "Epoch 297/500\n",
      "453/453 [==============================] - 0s 863us/sample - loss: 0.3064 - accuracy: 0.9448\n",
      "Epoch 298/500\n",
      "453/453 [==============================] - 0s 579us/sample - loss: 0.3091 - accuracy: 0.9448\n",
      "Epoch 299/500\n",
      "453/453 [==============================] - 0s 467us/sample - loss: 0.2982 - accuracy: 0.9492\n",
      "Epoch 300/500\n",
      "453/453 [==============================] - 0s 515us/sample - loss: 0.2950 - accuracy: 0.9470\n",
      "Epoch 301/500\n",
      "453/453 [==============================] - 0s 808us/sample - loss: 0.2922 - accuracy: 0.9492\n",
      "Epoch 302/500\n",
      "453/453 [==============================] - 0s 578us/sample - loss: 0.2910 - accuracy: 0.9492\n",
      "Epoch 303/500\n",
      "453/453 [==============================] - 0s 555us/sample - loss: 0.2884 - accuracy: 0.9470\n",
      "Epoch 304/500\n",
      "453/453 [==============================] - 0s 516us/sample - loss: 0.2851 - accuracy: 0.9492\n",
      "Epoch 305/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "453/453 [==============================] - 0s 498us/sample - loss: 0.2824 - accuracy: 0.9448\n",
      "Epoch 306/500\n",
      "453/453 [==============================] - 0s 702us/sample - loss: 0.2804 - accuracy: 0.9470\n",
      "Epoch 307/500\n",
      "453/453 [==============================] - 0s 531us/sample - loss: 0.2792 - accuracy: 0.9470\n",
      "Epoch 308/500\n",
      "453/453 [==============================] - 0s 517us/sample - loss: 0.2770 - accuracy: 0.9426\n",
      "Epoch 309/500\n",
      "453/453 [==============================] - 0s 531us/sample - loss: 0.2757 - accuracy: 0.9470\n",
      "Epoch 310/500\n",
      "453/453 [==============================] - 0s 605us/sample - loss: 0.2729 - accuracy: 0.9514\n",
      "Epoch 311/500\n",
      "453/453 [==============================] - 0s 487us/sample - loss: 0.2708 - accuracy: 0.9492\n",
      "Epoch 312/500\n",
      "453/453 [==============================] - 0s 471us/sample - loss: 0.2687 - accuracy: 0.9492\n",
      "Epoch 313/500\n",
      "453/453 [==============================] - 0s 505us/sample - loss: 0.2666 - accuracy: 0.9492\n",
      "Epoch 314/500\n",
      "453/453 [==============================] - 0s 469us/sample - loss: 0.2660 - accuracy: 0.9514\n",
      "Epoch 315/500\n",
      "453/453 [==============================] - 0s 515us/sample - loss: 0.2632 - accuracy: 0.9514\n",
      "Epoch 316/500\n",
      "453/453 [==============================] - 0s 482us/sample - loss: 0.2614 - accuracy: 0.9492\n",
      "Epoch 317/500\n",
      "453/453 [==============================] - 0s 485us/sample - loss: 0.2600 - accuracy: 0.9514\n",
      "Epoch 318/500\n",
      "453/453 [==============================] - 0s 482us/sample - loss: 0.2579 - accuracy: 0.9470\n",
      "Epoch 319/500\n",
      "453/453 [==============================] - 0s 471us/sample - loss: 0.2561 - accuracy: 0.9492\n",
      "Epoch 320/500\n",
      "453/453 [==============================] - 0s 504us/sample - loss: 0.2548 - accuracy: 0.9514\n",
      "Epoch 321/500\n",
      "453/453 [==============================] - 0s 504us/sample - loss: 0.2539 - accuracy: 0.9514\n",
      "Epoch 322/500\n",
      "453/453 [==============================] - 0s 459us/sample - loss: 0.2525 - accuracy: 0.9514\n",
      "Epoch 323/500\n",
      "453/453 [==============================] - 0s 464us/sample - loss: 0.2569 - accuracy: 0.9492\n",
      "Epoch 324/500\n",
      "453/453 [==============================] - 0s 463us/sample - loss: 0.2527 - accuracy: 0.9492\n",
      "Epoch 325/500\n",
      "453/453 [==============================] - 0s 510us/sample - loss: 0.2523 - accuracy: 0.9426\n",
      "Epoch 326/500\n",
      "453/453 [==============================] - 0s 468us/sample - loss: 0.2524 - accuracy: 0.9470\n",
      "Epoch 327/500\n",
      "453/453 [==============================] - 0s 454us/sample - loss: 0.2496 - accuracy: 0.9492\n",
      "Epoch 328/500\n",
      "453/453 [==============================] - 0s 472us/sample - loss: 0.2479 - accuracy: 0.9470\n",
      "Epoch 329/500\n",
      "453/453 [==============================] - 0s 456us/sample - loss: 0.2477 - accuracy: 0.9536\n",
      "Epoch 330/500\n",
      "453/453 [==============================] - 0s 466us/sample - loss: 0.2459 - accuracy: 0.9470\n",
      "Epoch 331/500\n",
      "453/453 [==============================] - 0s 454us/sample - loss: 0.2418 - accuracy: 0.9448\n",
      "Epoch 332/500\n",
      "453/453 [==============================] - 0s 472us/sample - loss: 0.2485 - accuracy: 0.9470\n",
      "Epoch 333/500\n",
      "453/453 [==============================] - 0s 458us/sample - loss: 0.2475 - accuracy: 0.9448\n",
      "Epoch 334/500\n",
      "453/453 [==============================] - 0s 478us/sample - loss: 0.2534 - accuracy: 0.9514\n",
      "Epoch 335/500\n",
      "453/453 [==============================] - 0s 465us/sample - loss: 0.2733 - accuracy: 0.9470\n",
      "Epoch 336/500\n",
      "453/453 [==============================] - 0s 476us/sample - loss: 0.2919 - accuracy: 0.9404\n",
      "Epoch 337/500\n",
      "453/453 [==============================] - 0s 462us/sample - loss: 0.3125 - accuracy: 0.9294\n",
      "Epoch 338/500\n",
      "453/453 [==============================] - 0s 456us/sample - loss: 0.2859 - accuracy: 0.9404\n",
      "Epoch 339/500\n",
      "453/453 [==============================] - 0s 456us/sample - loss: 0.2652 - accuracy: 0.9492\n",
      "Epoch 340/500\n",
      "453/453 [==============================] - 0s 468us/sample - loss: 0.2515 - accuracy: 0.9470\n",
      "Epoch 341/500\n",
      "453/453 [==============================] - 0s 454us/sample - loss: 0.2594 - accuracy: 0.9470\n",
      "Epoch 342/500\n",
      "453/453 [==============================] - 0s 471us/sample - loss: 0.2658 - accuracy: 0.9426\n",
      "Epoch 343/500\n",
      "453/453 [==============================] - 0s 467us/sample - loss: 0.2906 - accuracy: 0.9360\n",
      "Epoch 344/500\n",
      "453/453 [==============================] - 0s 463us/sample - loss: 0.2629 - accuracy: 0.9448\n",
      "Epoch 345/500\n",
      "453/453 [==============================] - 0s 479us/sample - loss: 0.2460 - accuracy: 0.9470\n",
      "Epoch 346/500\n",
      "453/453 [==============================] - 0s 460us/sample - loss: 0.2388 - accuracy: 0.9492\n",
      "Epoch 347/500\n",
      "453/453 [==============================] - 0s 480us/sample - loss: 0.2287 - accuracy: 0.9536\n",
      "Epoch 348/500\n",
      "453/453 [==============================] - 0s 465us/sample - loss: 0.2275 - accuracy: 0.9514\n",
      "Epoch 349/500\n",
      "453/453 [==============================] - 0s 458us/sample - loss: 0.2224 - accuracy: 0.9514\n",
      "Epoch 350/500\n",
      "453/453 [==============================] - 0s 476us/sample - loss: 0.2213 - accuracy: 0.9536\n",
      "Epoch 351/500\n",
      "453/453 [==============================] - 0s 488us/sample - loss: 0.2193 - accuracy: 0.9536\n",
      "Epoch 352/500\n",
      "453/453 [==============================] - 0s 467us/sample - loss: 0.2197 - accuracy: 0.9514\n",
      "Epoch 353/500\n",
      "453/453 [==============================] - 0s 465us/sample - loss: 0.2158 - accuracy: 0.9514\n",
      "Epoch 354/500\n",
      "453/453 [==============================] - 0s 458us/sample - loss: 0.2123 - accuracy: 0.9514\n",
      "Epoch 355/500\n",
      "453/453 [==============================] - 0s 480us/sample - loss: 0.2122 - accuracy: 0.9492\n",
      "Epoch 356/500\n",
      "453/453 [==============================] - 0s 467us/sample - loss: 0.2155 - accuracy: 0.9536\n",
      "Epoch 357/500\n",
      "453/453 [==============================] - 0s 458us/sample - loss: 0.2118 - accuracy: 0.9514\n",
      "Epoch 358/500\n",
      "453/453 [==============================] - 0s 462us/sample - loss: 0.2111 - accuracy: 0.9536\n",
      "Epoch 359/500\n",
      "453/453 [==============================] - 0s 454us/sample - loss: 0.2121 - accuracy: 0.9514\n",
      "Epoch 360/500\n",
      "453/453 [==============================] - 0s 467us/sample - loss: 0.2090 - accuracy: 0.9492\n",
      "Epoch 361/500\n",
      "453/453 [==============================] - 0s 451us/sample - loss: 0.2072 - accuracy: 0.9514\n",
      "Epoch 362/500\n",
      "453/453 [==============================] - 0s 469us/sample - loss: 0.2046 - accuracy: 0.9536\n",
      "Epoch 363/500\n",
      "453/453 [==============================] - 0s 464us/sample - loss: 0.2037 - accuracy: 0.9536\n",
      "Epoch 364/500\n",
      "453/453 [==============================] - 0s 465us/sample - loss: 0.2028 - accuracy: 0.9514\n",
      "Epoch 365/500\n",
      "453/453 [==============================] - 0s 467us/sample - loss: 0.2010 - accuracy: 0.9492\n",
      "Epoch 366/500\n",
      "453/453 [==============================] - 0s 465us/sample - loss: 0.2000 - accuracy: 0.9536\n",
      "Epoch 367/500\n",
      "453/453 [==============================] - 0s 471us/sample - loss: 0.1983 - accuracy: 0.9492\n",
      "Epoch 368/500\n",
      "453/453 [==============================] - 0s 473us/sample - loss: 0.1975 - accuracy: 0.9514\n",
      "Epoch 369/500\n",
      "453/453 [==============================] - 0s 470us/sample - loss: 0.1954 - accuracy: 0.9536\n",
      "Epoch 370/500\n",
      "453/453 [==============================] - 0s 462us/sample - loss: 0.1946 - accuracy: 0.9514\n",
      "Epoch 371/500\n",
      "453/453 [==============================] - 0s 460us/sample - loss: 0.1933 - accuracy: 0.9492\n",
      "Epoch 372/500\n",
      "453/453 [==============================] - 0s 467us/sample - loss: 0.1930 - accuracy: 0.9514\n",
      "Epoch 373/500\n",
      "453/453 [==============================] - 0s 465us/sample - loss: 0.1924 - accuracy: 0.9514\n",
      "Epoch 374/500\n",
      "453/453 [==============================] - 0s 457us/sample - loss: 0.1916 - accuracy: 0.9514\n",
      "Epoch 375/500\n",
      "453/453 [==============================] - 0s 462us/sample - loss: 0.1903 - accuracy: 0.9492\n",
      "Epoch 376/500\n",
      "453/453 [==============================] - 0s 471us/sample - loss: 0.1890 - accuracy: 0.9514\n",
      "Epoch 377/500\n",
      "453/453 [==============================] - 0s 460us/sample - loss: 0.1876 - accuracy: 0.9514\n",
      "Epoch 378/500\n",
      "453/453 [==============================] - 0s 476us/sample - loss: 0.1866 - accuracy: 0.9536\n",
      "Epoch 379/500\n",
      "453/453 [==============================] - 0s 476us/sample - loss: 0.1855 - accuracy: 0.9536\n",
      "Epoch 380/500\n",
      "453/453 [==============================] - 0s 478us/sample - loss: 0.1851 - accuracy: 0.9536\n",
      "Epoch 381/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "453/453 [==============================] - 0s 473us/sample - loss: 0.1842 - accuracy: 0.9536\n",
      "Epoch 382/500\n",
      "453/453 [==============================] - 0s 469us/sample - loss: 0.1829 - accuracy: 0.9536\n",
      "Epoch 383/500\n",
      "453/453 [==============================] - 0s 456us/sample - loss: 0.1826 - accuracy: 0.9536\n",
      "Epoch 384/500\n",
      "453/453 [==============================] - 0s 471us/sample - loss: 0.1819 - accuracy: 0.9536\n",
      "Epoch 385/500\n",
      "453/453 [==============================] - 0s 456us/sample - loss: 0.1820 - accuracy: 0.9514\n",
      "Epoch 386/500\n",
      "453/453 [==============================] - 0s 473us/sample - loss: 0.1810 - accuracy: 0.9514\n",
      "Epoch 387/500\n",
      "453/453 [==============================] - 0s 467us/sample - loss: 0.1800 - accuracy: 0.9492\n",
      "Epoch 388/500\n",
      "453/453 [==============================] - 0s 441us/sample - loss: 0.1792 - accuracy: 0.9514\n",
      "Epoch 389/500\n",
      "453/453 [==============================] - 0s 473us/sample - loss: 0.1799 - accuracy: 0.9514\n",
      "Epoch 390/500\n",
      "453/453 [==============================] - 0s 460us/sample - loss: 0.1775 - accuracy: 0.9492\n",
      "Epoch 391/500\n",
      "453/453 [==============================] - 0s 463us/sample - loss: 0.1764 - accuracy: 0.9514\n",
      "Epoch 392/500\n",
      "453/453 [==============================] - 0s 473us/sample - loss: 0.1767 - accuracy: 0.9492\n",
      "Epoch 393/500\n",
      "453/453 [==============================] - 0s 472us/sample - loss: 0.1793 - accuracy: 0.9514\n",
      "Epoch 394/500\n",
      "453/453 [==============================] - 0s 476us/sample - loss: 0.1768 - accuracy: 0.9514\n",
      "Epoch 395/500\n",
      "453/453 [==============================] - 0s 462us/sample - loss: 0.1831 - accuracy: 0.9514\n",
      "Epoch 396/500\n",
      "453/453 [==============================] - 0s 456us/sample - loss: 0.1846 - accuracy: 0.9492\n",
      "Epoch 397/500\n",
      "453/453 [==============================] - 0s 465us/sample - loss: 0.1868 - accuracy: 0.9514\n",
      "Epoch 398/500\n",
      "453/453 [==============================] - 0s 469us/sample - loss: 0.2068 - accuracy: 0.9448\n",
      "Epoch 399/500\n",
      "453/453 [==============================] - 0s 462us/sample - loss: 0.2004 - accuracy: 0.9470\n",
      "Epoch 400/500\n",
      "453/453 [==============================] - 0s 474us/sample - loss: 0.1932 - accuracy: 0.9470\n",
      "Epoch 401/500\n",
      "453/453 [==============================] - 0s 456us/sample - loss: 0.1947 - accuracy: 0.9470\n",
      "Epoch 402/500\n",
      "453/453 [==============================] - 0s 460us/sample - loss: 0.1930 - accuracy: 0.9492\n",
      "Epoch 403/500\n",
      "453/453 [==============================] - 0s 465us/sample - loss: 0.1831 - accuracy: 0.9514\n",
      "Epoch 404/500\n",
      "453/453 [==============================] - 0s 473us/sample - loss: 0.1815 - accuracy: 0.9514\n",
      "Epoch 405/500\n",
      "453/453 [==============================] - 0s 473us/sample - loss: 0.1763 - accuracy: 0.9514\n",
      "Epoch 406/500\n",
      "453/453 [==============================] - 0s 451us/sample - loss: 0.1731 - accuracy: 0.9536\n",
      "Epoch 407/500\n",
      "453/453 [==============================] - 0s 465us/sample - loss: 0.1699 - accuracy: 0.9536\n",
      "Epoch 408/500\n",
      "453/453 [==============================] - 0s 473us/sample - loss: 0.1682 - accuracy: 0.9492\n",
      "Epoch 409/500\n",
      "453/453 [==============================] - 0s 471us/sample - loss: 0.1669 - accuracy: 0.9492 - loss: 0.1687 - accuracy: 0.94\n",
      "Epoch 410/500\n",
      "453/453 [==============================] - 0s 462us/sample - loss: 0.1655 - accuracy: 0.9514\n",
      "Epoch 411/500\n",
      "453/453 [==============================] - 0s 458us/sample - loss: 0.1646 - accuracy: 0.9514\n",
      "Epoch 412/500\n",
      "453/453 [==============================] - 0s 465us/sample - loss: 0.1641 - accuracy: 0.9536\n",
      "Epoch 413/500\n",
      "453/453 [==============================] - 0s 454us/sample - loss: 0.1631 - accuracy: 0.9514\n",
      "Epoch 414/500\n",
      "453/453 [==============================] - 0s 463us/sample - loss: 0.1622 - accuracy: 0.9536\n",
      "Epoch 415/500\n",
      "453/453 [==============================] - 0s 480us/sample - loss: 0.1612 - accuracy: 0.9514\n",
      "Epoch 416/500\n",
      "453/453 [==============================] - 0s 525us/sample - loss: 0.1607 - accuracy: 0.9536\n",
      "Epoch 417/500\n",
      "453/453 [==============================] - 0s 478us/sample - loss: 0.1595 - accuracy: 0.9514\n",
      "Epoch 418/500\n",
      "453/453 [==============================] - 0s 462us/sample - loss: 0.1587 - accuracy: 0.9536\n",
      "Epoch 419/500\n",
      "453/453 [==============================] - 0s 495us/sample - loss: 0.1579 - accuracy: 0.9536\n",
      "Epoch 420/500\n",
      "453/453 [==============================] - 0s 491us/sample - loss: 0.1570 - accuracy: 0.9514\n",
      "Epoch 421/500\n",
      "453/453 [==============================] - 0s 466us/sample - loss: 0.1565 - accuracy: 0.9536\n",
      "Epoch 422/500\n",
      "453/453 [==============================] - 0s 471us/sample - loss: 0.1562 - accuracy: 0.9536\n",
      "Epoch 423/500\n",
      "453/453 [==============================] - 0s 465us/sample - loss: 0.1554 - accuracy: 0.9514\n",
      "Epoch 424/500\n",
      "453/453 [==============================] - 0s 478us/sample - loss: 0.1547 - accuracy: 0.9536\n",
      "Epoch 425/500\n",
      "453/453 [==============================] - 0s 507us/sample - loss: 0.1546 - accuracy: 0.9514\n",
      "Epoch 426/500\n",
      "453/453 [==============================] - 0s 471us/sample - loss: 0.1544 - accuracy: 0.9492\n",
      "Epoch 427/500\n",
      "453/453 [==============================] - 0s 471us/sample - loss: 0.1545 - accuracy: 0.9536\n",
      "Epoch 428/500\n",
      "453/453 [==============================] - 0s 465us/sample - loss: 0.1532 - accuracy: 0.9536\n",
      "Epoch 429/500\n",
      "453/453 [==============================] - 0s 482us/sample - loss: 0.1511 - accuracy: 0.9492\n",
      "Epoch 430/500\n",
      "453/453 [==============================] - 0s 469us/sample - loss: 0.1518 - accuracy: 0.9536\n",
      "Epoch 431/500\n",
      "453/453 [==============================] - 0s 473us/sample - loss: 0.1521 - accuracy: 0.9470\n",
      "Epoch 432/500\n",
      "453/453 [==============================] - 0s 471us/sample - loss: 0.1511 - accuracy: 0.9514\n",
      "Epoch 433/500\n",
      "453/453 [==============================] - 0s 476us/sample - loss: 0.1501 - accuracy: 0.9514\n",
      "Epoch 434/500\n",
      "453/453 [==============================] - 0s 509us/sample - loss: 0.1494 - accuracy: 0.9514\n",
      "Epoch 435/500\n",
      "453/453 [==============================] - 0s 526us/sample - loss: 0.1489 - accuracy: 0.9514\n",
      "Epoch 436/500\n",
      "453/453 [==============================] - 0s 509us/sample - loss: 0.1478 - accuracy: 0.9536\n",
      "Epoch 437/500\n",
      "453/453 [==============================] - 0s 509us/sample - loss: 0.1475 - accuracy: 0.9536\n",
      "Epoch 438/500\n",
      "453/453 [==============================] - 0s 485us/sample - loss: 0.1470 - accuracy: 0.9492\n",
      "Epoch 439/500\n",
      "453/453 [==============================] - 0s 641us/sample - loss: 0.1464 - accuracy: 0.9448\n",
      "Epoch 440/500\n",
      "453/453 [==============================] - 0s 511us/sample - loss: 0.1469 - accuracy: 0.9470\n",
      "Epoch 441/500\n",
      "453/453 [==============================] - 0s 488us/sample - loss: 0.1459 - accuracy: 0.9492\n",
      "Epoch 442/500\n",
      "453/453 [==============================] - 0s 555us/sample - loss: 0.1458 - accuracy: 0.9514\n",
      "Epoch 443/500\n",
      "453/453 [==============================] - 0s 543us/sample - loss: 0.1445 - accuracy: 0.9448\n",
      "Epoch 444/500\n",
      "453/453 [==============================] - 0s 517us/sample - loss: 0.1445 - accuracy: 0.9426\n",
      "Epoch 445/500\n",
      "453/453 [==============================] - 0s 480us/sample - loss: 0.1439 - accuracy: 0.9470\n",
      "Epoch 446/500\n",
      "453/453 [==============================] - 0s 509us/sample - loss: 0.1436 - accuracy: 0.9492\n",
      "Epoch 447/500\n",
      "453/453 [==============================] - 0s 506us/sample - loss: 0.1433 - accuracy: 0.9470\n",
      "Epoch 448/500\n",
      "453/453 [==============================] - 0s 504us/sample - loss: 0.1436 - accuracy: 0.9492\n",
      "Epoch 449/500\n",
      "453/453 [==============================] - 0s 501us/sample - loss: 0.1428 - accuracy: 0.9470\n",
      "Epoch 450/500\n",
      "453/453 [==============================] - 0s 504us/sample - loss: 0.1422 - accuracy: 0.9470\n",
      "Epoch 451/500\n",
      "453/453 [==============================] - 0s 564us/sample - loss: 0.1413 - accuracy: 0.9470\n",
      "Epoch 452/500\n",
      "453/453 [==============================] - 0s 493us/sample - loss: 0.1406 - accuracy: 0.9514\n",
      "Epoch 453/500\n",
      "453/453 [==============================] - 0s 493us/sample - loss: 0.1404 - accuracy: 0.9492\n",
      "Epoch 454/500\n",
      "453/453 [==============================] - 0s 476us/sample - loss: 0.1406 - accuracy: 0.9514\n",
      "Epoch 455/500\n",
      "453/453 [==============================] - 0s 484us/sample - loss: 0.1399 - accuracy: 0.9448\n",
      "Epoch 456/500\n",
      "453/453 [==============================] - 0s 473us/sample - loss: 0.1394 - accuracy: 0.9492\n",
      "Epoch 457/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "453/453 [==============================] - 0s 496us/sample - loss: 0.1384 - accuracy: 0.9470\n",
      "Epoch 458/500\n",
      "453/453 [==============================] - 0s 462us/sample - loss: 0.1383 - accuracy: 0.9492\n",
      "Epoch 459/500\n",
      "453/453 [==============================] - 0s 484us/sample - loss: 0.1378 - accuracy: 0.9448\n",
      "Epoch 460/500\n",
      "453/453 [==============================] - 0s 522us/sample - loss: 0.1375 - accuracy: 0.9470\n",
      "Epoch 461/500\n",
      "453/453 [==============================] - 0s 513us/sample - loss: 0.1366 - accuracy: 0.9470\n",
      "Epoch 462/500\n",
      "453/453 [==============================] - 0s 470us/sample - loss: 0.1363 - accuracy: 0.9492\n",
      "Epoch 463/500\n",
      "453/453 [==============================] - 0s 478us/sample - loss: 0.1353 - accuracy: 0.9492\n",
      "Epoch 464/500\n",
      "453/453 [==============================] - 0s 509us/sample - loss: 0.1363 - accuracy: 0.9448\n",
      "Epoch 465/500\n",
      "453/453 [==============================] - 0s 541us/sample - loss: 0.1364 - accuracy: 0.9492\n",
      "Epoch 466/500\n",
      "453/453 [==============================] - 0s 493us/sample - loss: 0.1358 - accuracy: 0.9536\n",
      "Epoch 467/500\n",
      "453/453 [==============================] - 0s 647us/sample - loss: 0.1351 - accuracy: 0.9514\n",
      "Epoch 468/500\n",
      "453/453 [==============================] - 0s 539us/sample - loss: 0.1344 - accuracy: 0.9492\n",
      "Epoch 469/500\n",
      "453/453 [==============================] - 0s 526us/sample - loss: 0.1339 - accuracy: 0.9492\n",
      "Epoch 470/500\n",
      "453/453 [==============================] - 0s 478us/sample - loss: 0.1342 - accuracy: 0.9470\n",
      "Epoch 471/500\n",
      "453/453 [==============================] - 0s 599us/sample - loss: 0.1332 - accuracy: 0.9536\n",
      "Epoch 472/500\n",
      "453/453 [==============================] - 0s 469us/sample - loss: 0.1331 - accuracy: 0.9514\n",
      "Epoch 473/500\n",
      "453/453 [==============================] - 0s 477us/sample - loss: 0.1329 - accuracy: 0.9514\n",
      "Epoch 474/500\n",
      "453/453 [==============================] - 0s 484us/sample - loss: 0.1321 - accuracy: 0.9536\n",
      "Epoch 475/500\n",
      "453/453 [==============================] - 0s 460us/sample - loss: 0.1317 - accuracy: 0.9536\n",
      "Epoch 476/500\n",
      "453/453 [==============================] - 0s 485us/sample - loss: 0.1314 - accuracy: 0.9448\n",
      "Epoch 477/500\n",
      "453/453 [==============================] - 0s 462us/sample - loss: 0.1310 - accuracy: 0.9492\n",
      "Epoch 478/500\n",
      "453/453 [==============================] - 0s 482us/sample - loss: 0.1321 - accuracy: 0.9536\n",
      "Epoch 479/500\n",
      "453/453 [==============================] - 0s 568us/sample - loss: 0.1318 - accuracy: 0.9514\n",
      "Epoch 480/500\n",
      "453/453 [==============================] - 0s 484us/sample - loss: 0.1312 - accuracy: 0.9492\n",
      "Epoch 481/500\n",
      "453/453 [==============================] - 0s 469us/sample - loss: 0.1305 - accuracy: 0.9514\n",
      "Epoch 482/500\n",
      "453/453 [==============================] - 0s 605us/sample - loss: 0.1295 - accuracy: 0.9514\n",
      "Epoch 483/500\n",
      "453/453 [==============================] - 0s 492us/sample - loss: 0.1295 - accuracy: 0.9514\n",
      "Epoch 484/500\n",
      "453/453 [==============================] - 0s 473us/sample - loss: 0.1287 - accuracy: 0.9514 - loss: 0.1252 - accuracy: 0.95\n",
      "Epoch 485/500\n",
      "453/453 [==============================] - 0s 471us/sample - loss: 0.1283 - accuracy: 0.9470\n",
      "Epoch 486/500\n",
      "453/453 [==============================] - 0s 637us/sample - loss: 0.1280 - accuracy: 0.9492\n",
      "Epoch 487/500\n",
      "453/453 [==============================] - 0s 801us/sample - loss: 0.1279 - accuracy: 0.9514\n",
      "Epoch 488/500\n",
      "453/453 [==============================] - 0s 506us/sample - loss: 0.1276 - accuracy: 0.9514\n",
      "Epoch 489/500\n",
      "453/453 [==============================] - 0s 478us/sample - loss: 0.1268 - accuracy: 0.9514\n",
      "Epoch 490/500\n",
      "453/453 [==============================] - 0s 471us/sample - loss: 0.1264 - accuracy: 0.9470\n",
      "Epoch 491/500\n",
      "453/453 [==============================] - 0s 467us/sample - loss: 0.1265 - accuracy: 0.9492\n",
      "Epoch 492/500\n",
      "453/453 [==============================] - 0s 492us/sample - loss: 0.1262 - accuracy: 0.9514\n",
      "Epoch 493/500\n",
      "453/453 [==============================] - 0s 465us/sample - loss: 0.1258 - accuracy: 0.9492\n",
      "Epoch 494/500\n",
      "453/453 [==============================] - 0s 473us/sample - loss: 0.1252 - accuracy: 0.9470\n",
      "Epoch 495/500\n",
      "453/453 [==============================] - 0s 458us/sample - loss: 0.1260 - accuracy: 0.9470\n",
      "Epoch 496/500\n",
      "453/453 [==============================] - 0s 589us/sample - loss: 0.1256 - accuracy: 0.9426\n",
      "Epoch 497/500\n",
      "453/453 [==============================] - 0s 975us/sample - loss: 0.1254 - accuracy: 0.9514\n",
      "Epoch 498/500\n",
      "453/453 [==============================] - 0s 480us/sample - loss: 0.1244 - accuracy: 0.9514\n",
      "Epoch 499/500\n",
      "453/453 [==============================] - 0s 480us/sample - loss: 0.1250 - accuracy: 0.9492\n",
      "Epoch 500/500\n",
      "453/453 [==============================] - 0s 509us/sample - loss: 0.1250 - accuracy: 0.9536\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(total_words, 64, input_length=max_sequence_len-1))\n",
    "model.add(Bidirectional(LSTM(20)))\n",
    "model.add(Dense(total_words, activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "history = model.fit(xs, ys, epochs=500, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def plot_graphs(history, string):\n",
    "    plt.plot(history.history[string])\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(string)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_graphs(history, 'accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Laurence went to dublin they as athy catchers water doing water at for at for for at lanigans ball ball ball ball entangled ball suppose ball doing at for at for for lanigans ball ball ball ball ball entangled ball suppose ball doing at for at for for lanigans ball ball ball ball ball entangled ball suppose ball doing at for at for for lanigans ball ball ball ball ball entangled ball suppose ball doing at for at for for lanigans ball ball ball ball ball entangled ball suppose ball doing at for at for for lanigans ball ball ball ball ball entangled ball\n"
     ]
    }
   ],
   "source": [
    "seed_text = \"Laurence went to dublin\"\n",
    "next_words = 100\n",
    "  \n",
    "for _ in range(next_words):\n",
    "\ttoken_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
    "\ttoken_list = pad_sequences([token_list], maxlen=max_sequence_len-1, padding='pre')\n",
    "\tpredicted = model.predict_classes(token_list, verbose=0)\n",
    "\toutput_word = \"\"\n",
    "\tfor word, index in tokenizer.word_index.items():\n",
    "\t\tif index == predicted:\n",
    "\t\t\toutput_word = word\n",
    "\t\t\tbreak\n",
    "\tseed_text += \" \" + output_word\n",
    "print(seed_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[134, 13, 59]]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seed_text = \"Laurence went to dublin\"\n",
    "\n",
    "tokenizer.texts_to_sequences([seed_text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
